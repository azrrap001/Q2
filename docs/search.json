[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Computing Practicals",
    "section": "",
    "text": "0.1 Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index</span>"
    ]
  },
  {
    "objectID": "index.html#running-code",
    "href": "index.html#running-code",
    "title": "Statistical Computing Practicals",
    "section": "0.2 Running Code",
    "text": "0.2 Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>index</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html",
    "href": "PRAC_1.html",
    "title": "2  Practical_One Solutions",
    "section": "",
    "text": "2.1 Question 1: Missing Values\n1st 6 rows of airquality dataset displayed below:\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\nDisplay rows with missing values:\n# Find rows with missing values  \nmissing_values &lt;- airquality[!complete.cases(airquality), ]  \nmissing_values\n\n    Ozone Solar.R Wind Temp Month Day\n5      NA      NA 14.3   56     5   5\n6      28      NA 14.9   66     5   6\n10     NA     194  8.6   69     5  10\n11      7      NA  6.9   74     5  11\n25     NA      66 16.6   57     5  25\n26     NA     266 14.9   58     5  26\n27     NA      NA  8.0   57     5  27\n32     NA     286  8.6   78     6   1\n33     NA     287  9.7   74     6   2\n34     NA     242 16.1   67     6   3\n35     NA     186  9.2   84     6   4\n36     NA     220  8.6   85     6   5\n37     NA     264 14.3   79     6   6\n39     NA     273  6.9   87     6   8\n42     NA     259 10.9   93     6  11\n43     NA     250  9.2   92     6  12\n45     NA     332 13.8   80     6  14\n46     NA     322 11.5   79     6  15\n52     NA     150  6.3   77     6  21\n53     NA      59  1.7   76     6  22\n54     NA      91  4.6   76     6  23\n55     NA     250  6.3   76     6  24\n56     NA     135  8.0   75     6  25\n57     NA     127  8.0   78     6  26\n58     NA      47 10.3   73     6  27\n59     NA      98 11.5   80     6  28\n60     NA      31 14.9   77     6  29\n61     NA     138  8.0   83     6  30\n65     NA     101 10.9   84     7   4\n72     NA     139  8.6   82     7  11\n75     NA     291 14.9   91     7  14\n83     NA     258  9.7   81     7  22\n84     NA     295 11.5   82     7  23\n96     78      NA  6.9   86     8   4\n97     35      NA  7.4   85     8   5\n98     66      NA  4.6   87     8   6\n102    NA     222  8.6   92     8  10\n103    NA     137 11.5   86     8  11\n107    NA      64 11.5   79     8  15\n115    NA     255 12.6   75     8  23\n119    NA     153  5.7   88     8  27\n150    NA     145 13.2   77     9  27",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html#question-2-find-mean-sdminmax-for-temperature-and-ozone-level",
    "href": "PRAC_1.html#question-2-find-mean-sdminmax-for-temperature-and-ozone-level",
    "title": "2  Practical_One Solutions",
    "section": "2.2 Question 2: Find mean, sd,min,max for Temperature and Ozone Level",
    "text": "2.2 Question 2: Find mean, sd,min,max for Temperature and Ozone Level\nOutput and Code for mean, sd, min, max for each of temperature and ozone level, accounting for missing values\nTemperature and Ozone Summary Statistics:\n\nmean_temp &lt;- round(mean(airquality$Temp, na.rm=T),2)\nsd_temp &lt;- round(sd(airquality$Temp, na.rm=T),2)\nmin_temp &lt;- min(airquality$Temp)\nmax_temp &lt;- max(airquality$Temp)\n\nmean_ozone &lt;- round(mean(airquality$Ozone, na.rm=T),2)\nsd_ozone &lt;- round(sd(airquality$Ozone, na.rm=T),2)\nmin_ozone &lt;- min(airquality$Ozone)\nmax_ozone &lt;- max(airquality$Ozone)\n\nOutput of summary statistics for Temperature and Ozone layer:\n\n\n[1] \"Temperature - Mean: 77.88\"\n\n\n[1] \"Temperature - SD: 9.47\"\n\n\n[1] \"Temperature - Min: 56\"\n\n\n[1] \"Temperature - Max: 97\"\n\n\n[1] \"Ozone - Mean: 42.13\"\n\n\n[1] \"Ozone - SD: 32.99\"\n\n\n[1] \"Ozone - Min: NA\"\n\n\n[1] \"Ozone - Max: NA\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html#question-3-linear-regression-for-cars-data",
    "href": "PRAC_1.html#question-3-linear-regression-for-cars-data",
    "title": "2  Practical_One Solutions",
    "section": "2.3 Question 3: Linear Regression for cars data",
    "text": "2.3 Question 3: Linear Regression for cars data\ncode displaying calculation of beta_hat estimates\n\n# Create the design matrix X (adding a column of ones for the intercept)  \nX &lt;- cbind(1, cars$speed)\n\n# Create the response variable Y  \nY &lt;- cars$dist  \n\n# Calculate the beta estimates using the  beta_hat formula \nbeta_hat &lt;- solve(t(X) %*% X) %*% (t(X) %*% Y)\nbeta_hat\n\n           [,1]\n[1,] -17.579095\n[2,]   3.932409\n\n\n\n\nThe beta estimates for B0 and B1 respectively are: -17.57909 3.932409 \n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html#question-4-linear-regression-for-cars-data",
    "href": "PRAC_1.html#question-4-linear-regression-for-cars-data",
    "title": "2  Practical_One Solutions",
    "section": "2.4 Question 4: Linear Regression for cars data",
    "text": "2.4 Question 4: Linear Regression for cars data\nCheck that the beta coefficients we obtained from the b_hat matrix is the same when fitting the linear regression model using lm() in R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "prac-day-four.html",
    "href": "prac-day-four.html",
    "title": "3  Prac Day 4",
    "section": "",
    "text": "SET-UP:\n\n# Install tidyverse if not already installed\nif (!requireNamespace(\"tidyverse\", quietly = TRUE)) {\n  install.packages(\"tidyverse\")\n}\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Install and load nycflights13 for flight data\nif (!requireNamespace(\"nycflights13\", quietly = TRUE)) {\n  install.packages(\"nycflights13\")\n}\nlibrary(nycflights13)\nlibrary(dplyr)  \nlibrary(tibble)\n\n\n4 Questions\n\nDisplay the flights dataset in an alternative format to simply printing it (i.e. running flights).\n\n\n# Convert flights dataframe to a tibble\nUtilsDataRSV::view_cols(flights)\n\n[1] \"year\"\n[1] 539\n[1] \"_____________________\"\n[1] \"month\"\n[1] 1 6 9 3 2\n[1] \"_____________________\"\n[1] \"day\"\n[1] 11 17 25 10 27\n[1] \"_____________________\"\n[1] \"dep_time\"\n[1] 1658 1005  157 1548   NA\n[1] \"_____________________\"\n[1] \"sched_dep_time\"\n[1] 2008 1013 1915 1240 2038\n[1] \"_____________________\"\n[1] \"dep_delay\"\n[1] -20 -33 423 367  NA\n[1] \"_____________________\"\n[1] \"arr_time\"\n[1]  309 2118 1704 1149   NA\n[1] \"_____________________\"\n[1] \"sched_arr_time\"\n[1] 1509  232 2338 2216 1902\n[1] \"_____________________\"\n[1] \"arr_delay\"\n[1] 396  -1 231 -32  NA\n[1] \"_____________________\"\n[1] \"carrier\"\n [1] \"VX\" \"F9\" \"WN\" \"HA\" \"EV\" \"AS\" \"UA\" \"MQ\" \"US\" \"DL\" \"OO\" \"AA\" \"B6\" \"9E\" \"FL\"\n[16] \"YV\"\n[1] \"_____________________\"\n[1] \"flight\"\n[1]  444 1338 3284  430 1096\n[1] \"_____________________\"\n[1] \"tailnum\"\n [1] \"N506UA\" \"N927WN\" \"N409AS\" \"N312US\" \"N338AT\" \"N722MQ\" \"N110UW\" \"N607SW\"\n [9] \"N69806\" \"N3FGAA\" \"N364SW\" \"N550NW\" \"N542US\" \"N669UA\" \"N5CNAA\" \"N404WN\"\n[17] \"N186US\" \"N851VA\" \"N759GS\" NA      \n[1] \"4024 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"origin\"\n[1] \"EWR\" \"JFK\" \"LGA\"\n[1] \"_____________________\"\n[1] \"dest\"\n [1] \"STT\" \"SYR\" \"PSP\" \"DAY\" \"MSP\" \"SFO\" \"TYS\" \"RSW\" \"ROC\" \"BDL\" \"PWM\" \"XNA\"\n[13] \"HNL\" \"JAC\" \"BGR\" \"SLC\" \"BUF\" \"CHO\" \"ORF\" \"GSO\"\n[1] \"85 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"air_time\"\n[1] 226 622 209 354  NA\n[1] \"_____________________\"\n[1] \"distance\"\n[1]  828 1747 1167  872  212\n[1] \"_____________________\"\n[1] \"hour\"\n[1]  6  9 16 12 10\n[1] \"_____________________\"\n[1] \"minute\"\n[1] 23 56 53 35 16\n[1] \"_____________________\"\n[1] \"time_hour\"\n [1] \"2013-08-14 09:00:00 EDT\" \"2013-05-19 22:00:00 EDT\"\n [3] \"2013-01-16 16:00:00 EST\" \"2013-08-20 05:00:00 EDT\"\n [5] \"2013-04-13 07:00:00 EDT\" \"2013-08-17 07:00:00 EDT\"\n [7] \"2013-01-19 08:00:00 EST\" \"2013-02-02 21:00:00 EST\"\n [9] \"2013-05-08 10:00:00 EDT\" \"2013-08-29 17:00:00 EDT\"\n[11] \"2013-06-28 17:00:00 EDT\" \"2013-07-10 07:00:00 EDT\"\n[13] \"2013-04-29 14:00:00 EDT\" \"2013-09-14 16:00:00 EDT\"\n[15] \"2013-04-23 20:00:00 EDT\" \"2013-04-02 21:00:00 EDT\"\n[17] \"2013-06-15 23:00:00 EDT\" \"2013-09-15 07:00:00 EDT\"\n[19] \"2013-08-09 06:00:00 EDT\" \"2013-09-28 23:00:00 EDT\"\n[1] \"6916 unique entries not displayed\"\n[1] \"_____________________\"\n\n\nWarning: Not all unique entries displayed for these non-numeric cols: tailnum,\ndest, time_hour\n\nflights &lt;- as_tibble(flights)\nflights\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nNow inspect unique values in each column to flights tibble\n\nUtilsDataRSV::view_cols(flights)\n\n[1] \"year\"\n[1] 1232\n[1] \"_____________________\"\n[1] \"month\"\n[1] 10  2  3  4  5\n[1] \"_____________________\"\n[1] \"day\"\n[1] 14 26 17 18  5\n[1] \"_____________________\"\n[1] \"dep_time\"\n[1] 1727  904  611 1626   NA\n[1] \"_____________________\"\n[1] \"sched_dep_time\"\n[1] 1207 1115 1437 1203 1544\n[1] \"_____________________\"\n[1] \"dep_delay\"\n[1] 151  98 142 324  NA\n[1] \"_____________________\"\n[1] \"arr_time\"\n[1] 1958 1835 1522 1111   NA\n[1] \"_____________________\"\n[1] \"sched_arr_time\"\n[1] 2221 1207 1049 1206 1844\n[1] \"_____________________\"\n[1] \"arr_delay\"\n[1] 244 183  57  16  NA\n[1] \"_____________________\"\n[1] \"carrier\"\n [1] \"WN\" \"OO\" \"AS\" \"FL\" \"DL\" \"US\" \"VX\" \"B6\" \"F9\" \"AA\" \"YV\" \"EV\" \"9E\" \"MQ\" \"UA\"\n[16] \"HA\"\n[1] \"_____________________\"\n[1] \"flight\"\n[1]  415 5254 4950 1222 1616\n[1] \"_____________________\"\n[1] \"tailnum\"\n [1] \"N3EFAA\" \"N549AA\" \"N613MQ\" \"N3738B\" \"N8974C\" \"N14953\" \"N810UA\" \"N994AT\"\n [9] \"N206UA\" \"N832AY\" \"N320AS\" \"N525VA\" \"N724SW\" \"N329AA\" \"N543AA\" \"N201AA\"\n[17] \"N784NC\" \"N940WN\" \"N334JB\" NA      \n[1] \"4024 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"origin\"\n[1] \"JFK\" \"LGA\" \"EWR\"\n[1] \"_____________________\"\n[1] \"dest\"\n [1] \"DSM\" \"LAS\" \"CLE\" \"RDU\" \"JAC\" \"PVD\" \"SDF\" \"MEM\" \"MTJ\" \"LAX\" \"BOS\" \"SJC\"\n[13] \"OMA\" \"SJU\" \"LGA\" \"DTW\" \"CVG\" \"PDX\" \"JAX\" \"ORF\"\n[1] \"85 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"air_time\"\n[1] 168  65 581 315  NA\n[1] \"_____________________\"\n[1] \"distance\"\n[1] 246 213 288 185 644\n[1] \"_____________________\"\n[1] \"hour\"\n[1]  6 21 15 22 17\n[1] \"_____________________\"\n[1] \"minute\"\n[1] 22 59 37 10  4\n[1] \"_____________________\"\n[1] \"time_hour\"\n [1] \"2013-05-23 07:00:00 EDT\" \"2013-07-25 09:00:00 EDT\"\n [3] \"2013-02-23 21:00:00 EST\" \"2013-01-08 20:00:00 EST\"\n [5] \"2013-07-12 13:00:00 EDT\" \"2013-04-06 13:00:00 EDT\"\n [7] \"2013-05-23 05:00:00 EDT\" \"2013-06-30 20:00:00 EDT\"\n [9] \"2013-08-02 23:00:00 EDT\" \"2013-11-08 12:00:00 EST\"\n[11] \"2013-11-04 07:00:00 EST\" \"2013-07-07 15:00:00 EDT\"\n[13] \"2013-06-24 14:00:00 EDT\" \"2013-11-05 20:00:00 EST\"\n[15] \"2013-04-18 14:00:00 EDT\" \"2013-09-07 05:00:00 EDT\"\n[17] \"2013-01-13 07:00:00 EST\" \"2013-01-21 10:00:00 EST\"\n[19] \"2013-12-10 16:00:00 EST\" \"2013-01-03 12:00:00 EST\"\n[1] \"6916 unique entries not displayed\"\n[1] \"_____________________\"\n\n\nWarning: Not all unique entries displayed for these non-numeric cols: tailnum,\ndest, time_hour\n\n\n\nRewrite the following code using dplyr and the pipe:\nThis is the code before transformation.\n\nflight1 &lt;- flights[flights$month == 1, ]\n(carrier_vec &lt;- unique(flight1$carrier))\n\n [1] \"UA\" \"AA\" \"B6\" \"DL\" \"EV\" \"MQ\" \"US\" \"WN\" \"VX\" \"FL\" \"AS\" \"9E\" \"F9\" \"HA\" \"YV\"\n[16] \"OO\"\n\ncarrier_dist_vec_mean &lt;- numeric(length(carrier_vec))\ncarrier_dist_vec_sd &lt;- numeric(length(carrier_vec))\nfor (i in seq_along(carrier_vec)) {\n  carrier_dist_vec_mean[i] &lt;- mean(\n    flight1$distance[flight1$carrier == carrier_vec[i]]\n   )\n  carrier_dist_vec_sd[i] &lt;- sd(\n    flight1$distance[flight1$carrier == carrier_vec[i]]\n  )\n}\ndist_tbl &lt;- tibble(\n  carrier = carrier_vec,\n  mean_distance = carrier_dist_vec_mean,\n  sd_distance = carrier_dist_vec_sd\n)\ndist_tbl[order(dist_tbl$mean_distance), ]\n\n# A tibble: 16 × 3\n   carrier mean_distance sd_distance\n   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n 1 YV               229          0  \n 2 9E               476.       334. \n 3 EV               522.       294. \n 4 US               536.       553. \n 5 MQ               566.       223. \n 6 FL               691.       142. \n 7 OO               733         NA  \n 8 WN               942.       496. \n 9 B6              1062.       681. \n10 DL              1220.       644. \n11 AA              1350.       626. \n12 UA              1462.       778. \n13 F9              1620          0  \n14 AS              2402          0  \n15 VX              2495.        98.2\n16 HA              4983          0  \n\n\n\nflights |&gt; \n  filter(month == \"1\") |&gt;  #Filter the data to include only flights from January\n  group_by(carrier) |&gt; #Group the data  to perform calc. for each carrier.\n  summarise(\n    mean_distance = mean(distance, na.rm=T),#ignore NA values \n    sd_distance = sd(distance, na.rm=T),\n  ) |&gt; \n  arrange(mean_distance)#ascending order \n\n# A tibble: 16 × 3\n   carrier mean_distance sd_distance\n   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n 1 YV               229          0  \n 2 9E               476.       334. \n 3 EV               522.       294. \n 4 US               536.       553. \n 5 MQ               566.       223. \n 6 FL               691.       142. \n 7 OO               733         NA  \n 8 WN               942.       496. \n 9 B6              1062.       681. \n10 DL              1220.       644. \n11 AA              1350.       626. \n12 UA              1462.       778. \n13 F9              1620          0  \n14 AS              2402          0  \n15 VX              2495.        98.2\n16 HA              4983          0  \n\n\nThis is the code after transformation using dplyr and the pipe:\nExplain why the standard deviation is NA for one carrier, and why it is 0 for others. Demonstrate your answer using code.\nStandard Deviation of NA occurs when observed flights has missing data in the distance column, and so when we calculate the standard deviation with those values we get an NA result.\nStandard Deviation of 0 indicates that all flights for a carrier have identical distances (no variability), leading to a standard deviation of 0. This could mean that carrier’s flights are operating under uniform conditions where they are scheduled to take the same route.\n\nbelow is the code demonstration:\n\nflights |&gt; \n  filter(month == \"1\") |&gt;  #Filter the data to include only flights from January\n  group_by(carrier) |&gt; #Group the data  to perform calc. for each carrier.\n  summarise(\n    sd_distance = sd(distance, na.rm=T),\n    distance = list(distance) #lists associated distance of sd_distance\n  ) |&gt; \n  #logical checks if either is TRUE row kept \nfilter(is.na(sd_distance)| sd_distance == 0)\n\n# A tibble: 5 × 3\n  carrier sd_distance distance  \n  &lt;chr&gt;         &lt;dbl&gt; &lt;list&gt;    \n1 AS                0 &lt;dbl [62]&gt;\n2 F9                0 &lt;dbl [59]&gt;\n3 HA                0 &lt;dbl [31]&gt;\n4 OO               NA &lt;dbl [1]&gt; \n5 YV                0 &lt;dbl [46]&gt;\n\n\nThe code filters January flights to find carriers with either NA or 0 standard deviations, displaying relevant results.\n\nUsing tidyr and dplyr where appropriate, construct a dataframe where the carriers are along the columns, and the rows are the average departure delay (dep_delay) flown by each carrier (carrier) in each month.\n\nflights |&gt; \n  group_by(carrier,month) |&gt; #groups data by month and carrier \n  summarise(\n    avg_dep_delay = mean(dep_delay)) |&gt; \n  pivot_wider(\n    names_from = carrier,\n    values_from = avg_dep_delay\n  )\n\n`summarise()` has grouped output by 'carrier'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 17\n   month  `9E`    AA     AS    B6    DL    EV    F9    FL    HA    MQ    OO\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1    NA    NA  7.35     NA    NA    NA 10     NA   54.4     NA  67  \n 2     2    NA    NA NA        NA    NA    NA NA     NA   17.4     NA  NA  \n 3     3    NA    NA  8.42     NA    NA    NA 16.8   NA    1.16    NA  NA  \n 4     4    NA    NA 11.3      NA    NA    NA 24.6   NA   -2.1     NA  NA  \n 5     5    NA    NA  6.77     NA    NA    NA 35.9   NA   -1.45    NA  NA  \n 6     6    NA    NA 13.1      NA    NA    NA 29.4   NA    1.47    NA  61  \n 7     7    NA    NA  2.42     NA    NA    NA 31.8   NA   -1.71    NA  NA  \n 8     8    NA    NA  2.87     NA    NA    NA 22.2   NA    1.68    NA  64  \n 9     9    NA    NA -4.52     NA    NA    NA NA     NA   -5.44    NA  NA  \n10    10    NA    NA  0.677    NA    NA    NA  9.70  NA   -5.10    NA  NA  \n11    11    NA    NA  3.08     NA    NA    NA NA     16.9 -5.44    NA   0.8\n12    12    NA    NA 18.0      NA    NA    NA 13.1   NA   -3.14    NA  NA  \n# ℹ 5 more variables: UA &lt;dbl&gt;, US &lt;dbl&gt;, VX &lt;dbl&gt;, WN &lt;dbl&gt;, YV &lt;dbl&gt;\n\n\nCalculate the proportion of flights that were delayed (dep_delay greater than 0) but arrived on or before time (arr_delay less than or equal to 0).\n\n\nflights |&gt; \n  summarise(\n    count = sum(dep_delay &gt;0 & arr_delay &lt;=0, na.rm = T),\n    total_flights = n(),\n    proportion = count/total_flights\n  )\n\n# A tibble: 1 × 3\n  count total_flights proportion\n  &lt;int&gt;         &lt;int&gt;      &lt;dbl&gt;\n1 35442        336776      0.105\n\n#alternatively since we are dealing with a logical expressions we can directly get \n#the proprotion by taking the mean \n\nflights |&gt; \n  summarise(proportion = mean(dep_delay &gt; 0 & arr_delay &lt;=0, na.rm=T ))\n\n# A tibble: 1 × 1\n  proportion\n       &lt;dbl&gt;\n1      0.108\n\n\nnote: summarise is helpful for calculating summary statistics for the entire dataset/ groups\n\nUsing the airlines and flights datasets, do the following, showing the output from each step:\n\n\nIdentify routes that more than one airline flies\nFor each such route, calculate the average arrival delay for each airline (exclude NAs). Find the names of these airlines.\nFor each such route, identify the airline with the worst and best average arrival delay.\nIdentify the route with the greatest difference between the best and worst performing airlines\nDetermine the reason for this difference",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Prac Day 4</span>"
    ]
  },
  {
    "objectID": "prac_2.html",
    "href": "prac_2.html",
    "title": "4  prac_2",
    "section": "",
    "text": "4.1 LOWESS PRACTICAL\nThe goal of Lowess smoothing is to create a smooth curve that captures the underlying trend of the data while accounting for local structures and variation.\nThis is especially useful in datasets like noisy sine waves where the true relationship is obscured by noise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>prac_2</span>"
    ]
  },
  {
    "objectID": "prac_2.html#lowess-practical",
    "href": "prac_2.html#lowess-practical",
    "title": "4  prac_2",
    "section": "",
    "text": "4.1.1 Steps to Implement Lowess Smoothing\n\nUnderstanding the data\n\nGoal: Gather the observed data pairs as (x1​,y1​),…,(xn​,yn​), where x represents the independent variable and y is the dependent variable. We will generate sequences for x and create the corresponding y values using a sine function with added noise.\n\n\nChoosing the Span\n\nGoal: Select a smoothing parameter (span) f where 0&lt;f&lt;1. This span determines how many neighboring points will influence the smoothed estimate for each xi\nCalculation k=⌈f⋅n⌉, where k is the number of closest neighbours used for point xi and n is the number of observations.\n\n\n\n\n\nComputing Weights - Goal: For each point xi , calculate the weight for each of its neighbors using the tricube kernel:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>prac_2</span>"
    ]
  },
  {
    "objectID": "prac_2.html#practical",
    "href": "prac_2.html#practical",
    "title": "4  prac_2",
    "section": "4.2 PRACTICAL",
    "text": "4.2 PRACTICAL\n\n#set seed to 1\nset.seed(1)\n\n#Generate simulated data \nn &lt;- 100\nx &lt;- seq(1:n)\ne &lt;- rnorm(n, mean = 0 , sd = 0.2)\ny &lt;- sin(x/10) + e\n\n#Implement the LOWESS Algorithm\ncustomLowess &lt;- function(x, y, f)\n{\n  nobs &lt;-  length(x)\n  smoothed_y &lt;- numeric(nobs) #Initialize storage for smoothed y values \n  \n  #determine k = number of closest neighbors based on the bandwidth (f)\n  k = floor(f * nobs)\n  \n  #compute weights \n  #Calculate dmax \n  for (i in 1:n){\n    #caclulate distance from current point \n    dist = abs(x - x[i]) #distance vector\n    sort_dist_indices &lt;-  order(dist) #give indices of sorted distance in ascending order \n    \n    #find k closest neighbours \n    near_indices &lt;- sort_dist_indices[1:k] #By taking the first k of these sorted indices, we get the indices of the nearest points\n    \n    #find corresponding co-ord for nearest neighbour points \n    x_neighbours &lt;-  x[near_indices]#closest points are at those indices\n    y_neighbours &lt;-  y[near_indices]\n    nearest_dist &lt;- dist[near_indices]\n    \n    #Compute weights\n    d_max &lt;- max(nearest_dist)\n    wj &lt;- (1-(abs(nearest_dist)/d_max)^3)^3\n    wj[abs(nearest_dist) &gt;= d_max] &lt;- 0 #condition is TRUE, the corresponding weight in the weights vector is set to 0\n    \n    X &lt;- cbind(1, x_neighbours)\n    W &lt;- diag(wj) # Create diagonal weight matrix  \n    \n    #regression estimates\n    beta_hat &lt;- solve(t(X) %*% W %*% X) %*% t(X) %*% W %*% y_neighbours\n    \n    smoothed_y[i] &lt;- beta_hat[1] + beta_hat[2] %*% x[i]\n    \n  }\n  return(list(x = x, smoothed_y =  smoothed_y))\n}\n\nCalling the above customLowess function and compare it with the built-in lowess() function with the same f value. Note: iter argument to 0\nBelow displays the plotted results for the customLowess function for f = 0.5\n\nresult &lt;- customLowess(x, y, f = 0.5)\n\n# Plot the original data  \nplot(y ~ x, main = \"LOWESS Smoothing\", xlab = \"X-axis\", ylab = \"Y-axis\", pch = 19) \n\n#add lowess line \nlines(result$x, result$smoothed_y, col = 'blue', lwd = 2)\n\n\n\n\n\n\n\n\nBelow displays the plotted results or the build-in Lowess function for f = 0.5\n\n# Plot the original data  \nplot(y ~ x, main = \"LOWESS Smoothing\", xlab = \"X-axis\", ylab = \"Y-axis\", pch = 19) \n\nlines(lowess(x, y, f=0.5, iter = 0))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>prac_2</span>"
    ]
  }
]