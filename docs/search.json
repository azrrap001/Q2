[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STATISTICAL COMPUTING PRACTICALS",
    "section": "",
    "text": "Here’s a quick overview of what you’ll find:\n\nPractical one : (PRAC_1.qmd)\n\nPractical Day Four which includes the lm() function done from first principles at the end: (prac-day-four.qmd)\n\nPractical two : (prac_2.qmd)\n\nHere is the link to my github repository : github repository",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>STATISTICAL COMPUTING PRACTICALS</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html",
    "href": "PRAC_1.html",
    "title": "2  Practical_One Solutions",
    "section": "",
    "text": "2.1 Question 1: Missing Values\n1st 6 rows of airquality dataset displayed below:\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\nDisplay rows with missing values:\n# Find rows with missing values  \nmissing_values &lt;- airquality[!complete.cases(airquality), ]  \nmissing_values\n\n    Ozone Solar.R Wind Temp Month Day\n5      NA      NA 14.3   56     5   5\n6      28      NA 14.9   66     5   6\n10     NA     194  8.6   69     5  10\n11      7      NA  6.9   74     5  11\n25     NA      66 16.6   57     5  25\n26     NA     266 14.9   58     5  26\n27     NA      NA  8.0   57     5  27\n32     NA     286  8.6   78     6   1\n33     NA     287  9.7   74     6   2\n34     NA     242 16.1   67     6   3\n35     NA     186  9.2   84     6   4\n36     NA     220  8.6   85     6   5\n37     NA     264 14.3   79     6   6\n39     NA     273  6.9   87     6   8\n42     NA     259 10.9   93     6  11\n43     NA     250  9.2   92     6  12\n45     NA     332 13.8   80     6  14\n46     NA     322 11.5   79     6  15\n52     NA     150  6.3   77     6  21\n53     NA      59  1.7   76     6  22\n54     NA      91  4.6   76     6  23\n55     NA     250  6.3   76     6  24\n56     NA     135  8.0   75     6  25\n57     NA     127  8.0   78     6  26\n58     NA      47 10.3   73     6  27\n59     NA      98 11.5   80     6  28\n60     NA      31 14.9   77     6  29\n61     NA     138  8.0   83     6  30\n65     NA     101 10.9   84     7   4\n72     NA     139  8.6   82     7  11\n75     NA     291 14.9   91     7  14\n83     NA     258  9.7   81     7  22\n84     NA     295 11.5   82     7  23\n96     78      NA  6.9   86     8   4\n97     35      NA  7.4   85     8   5\n98     66      NA  4.6   87     8   6\n102    NA     222  8.6   92     8  10\n103    NA     137 11.5   86     8  11\n107    NA      64 11.5   79     8  15\n115    NA     255 12.6   75     8  23\n119    NA     153  5.7   88     8  27\n150    NA     145 13.2   77     9  27",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html#question-2-find-mean-sdminmax-for-temperature-and-ozone-level",
    "href": "PRAC_1.html#question-2-find-mean-sdminmax-for-temperature-and-ozone-level",
    "title": "2  Practical_One Solutions",
    "section": "2.2 Question 2: Find mean, sd,min,max for Temperature and Ozone Level",
    "text": "2.2 Question 2: Find mean, sd,min,max for Temperature and Ozone Level\nOutput and Code for mean, sd, min, max for each of temperature and ozone level, accounting for missing values\nTemperature and Ozone Summary Statistics:\n\nmean_temp &lt;- round(mean(airquality$Temp, na.rm=T),2)\nsd_temp &lt;- round(sd(airquality$Temp, na.rm=T),2)\nmin_temp &lt;- min(airquality$Temp, na.rm=T)\nmax_temp &lt;- max(airquality$Temp, na.rm=T)\n\nmean_ozone &lt;- round(mean(airquality$Ozone, na.rm=T),2)\nsd_ozone &lt;- round(sd(airquality$Ozone, na.rm=T),2)\nmin_ozone &lt;- min(airquality$Ozone, na.rm=T)\nmax_ozone &lt;- max(airquality$Ozone,na.rm=T)\n\nOutput of summary statistics for Temperature and Ozone layer:\n\n\n[1] \"Temperature - Mean: 77.88\"\n\n\n[1] \"Temperature - SD: 9.47\"\n\n\n[1] \"Temperature - Min: 56\"\n\n\n[1] \"Temperature - Max: 97\"\n\n\n[1] \"Ozone - Mean: 42.13\"\n\n\n[1] \"Ozone - SD: 32.99\"\n\n\n[1] \"Ozone - Min: 1\"\n\n\n[1] \"Ozone - Max: 168\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html#question-3-linear-regression-for-cars-data",
    "href": "PRAC_1.html#question-3-linear-regression-for-cars-data",
    "title": "2  Practical_One Solutions",
    "section": "2.3 Question 3: Linear Regression for cars data",
    "text": "2.3 Question 3: Linear Regression for cars data\ncode displaying calculation of beta_hat estimates\n\n# Create the design matrix X (adding a column of ones for the intercept)  \nX &lt;- cbind(1, cars$speed)\n\n# Create the response variable Y  \nY &lt;- cars$dist  \n\n# Calculate the beta estimates using the  beta_hat formula \nbeta_hat &lt;- solve(t(X) %*% X) %*% (t(X) %*% Y)\nbeta_hat\n\n           [,1]\n[1,] -17.579095\n[2,]   3.932409\n\n\n\n\nThe beta estimates for B0 and B1 respectively are: -17.57909 3.932409 \n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "PRAC_1.html#question-4-linear-regression-for-cars-data",
    "href": "PRAC_1.html#question-4-linear-regression-for-cars-data",
    "title": "2  Practical_One Solutions",
    "section": "2.4 Question 4: Linear Regression for cars data",
    "text": "2.4 Question 4: Linear Regression for cars data\nCheck that the beta coefficients we obtained from the b_hat matrix is the same when fitting the linear regression model using lm() in R.\n\n model &lt;- lm(cars$dist~ cars$speed)\n summary(model)\n\n\nCall:\nlm(formula = cars$dist ~ cars$speed)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \ncars$speed    3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Practical_One Solutions</span>"
    ]
  },
  {
    "objectID": "prac-day-four.html",
    "href": "prac-day-four.html",
    "title": "3  Prac Day 4",
    "section": "",
    "text": "4 Questions\n# Convert flights dataframe to a tibble\nUtilsDataRSV::view_cols(flights)\n\n[1] \"year\"\n[1] 1765\n[1] \"_____________________\"\n[1] \"month\"\n[1] 2 6 9 4 3\n[1] \"_____________________\"\n[1] \"day\"\n[1]  1 30  5  3 11\n[1] \"_____________________\"\n[1] \"dep_time\"\n[1]  527  303 2020 1911   NA\n[1] \"_____________________\"\n[1] \"sched_dep_time\"\n[1] 1530 1545 1505 1709 1120\n[1] \"_____________________\"\n[1] \"dep_delay\"\n[1] 179 269 372  -1  NA\n[1] \"_____________________\"\n[1] \"arr_time\"\n[1]  820 1338  659 1747   NA\n[1] \"_____________________\"\n[1] \"sched_arr_time\"\n[1]  641 2208 1815  711  101\n[1] \"_____________________\"\n[1] \"arr_delay\"\n[1] 780 300 516 393  NA\n[1] \"_____________________\"\n[1] \"carrier\"\n [1] \"UA\" \"B6\" \"AS\" \"YV\" \"WN\" \"US\" \"VX\" \"9E\" \"OO\" \"DL\" \"F9\" \"EV\" \"AA\" \"FL\" \"MQ\"\n[16] \"HA\"\n[1] \"_____________________\"\n[1] \"flight\"\n[1] 1912  466 1180 1523 2013\n[1] \"_____________________\"\n[1] \"tailnum\"\n [1] \"N71411\" \"N151UW\" \"N805MQ\" \"N7734H\" \"N503US\" \"N3ATAA\" \"N959UW\" \"N8603F\"\n [9] \"N813SK\" \"N8604K\" \"N713EV\" \"N639AA\" \"N407UA\" \"N77012\" \"N4XEAA\" \"N564UW\"\n[17] \"N3EKAA\" \"N3750D\" \"N110UW\" NA      \n[1] \"4024 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"origin\"\n[1] \"EWR\" \"JFK\" \"LGA\"\n[1] \"_____________________\"\n[1] \"dest\"\n [1] \"ANC\" \"JAC\" \"SRQ\" \"OMA\" \"MCO\" \"BNA\" \"MSP\" \"LEX\" \"BWI\" \"BTV\" \"OAK\" \"SMF\"\n[13] \"SFO\" \"TYS\" \"RIC\" \"LAS\" \"ATL\" \"AUS\" \"FLL\" \"BHM\"\n[1] \"85 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"air_time\"\n[1] 314  63 575 278  NA\n[1] \"_____________________\"\n[1] \"distance\"\n[1]  740 1826 1065   94 2465\n[1] \"_____________________\"\n[1] \"hour\"\n[1] 13 11 15  5  6\n[1] \"_____________________\"\n[1] \"minute\"\n[1] 53 37 26 17  0\n[1] \"_____________________\"\n[1] \"time_hour\"\n [1] \"2013-01-11 16:00:00 EST\" \"2013-08-31 06:00:00 EDT\"\n [3] \"2013-10-03 14:00:00 EDT\" \"2013-10-26 05:00:00 EDT\"\n [5] \"2013-05-18 09:00:00 EDT\" \"2013-02-24 07:00:00 EST\"\n [7] \"2013-11-10 16:00:00 EST\" \"2013-11-26 21:00:00 EST\"\n [9] \"2013-12-26 12:00:00 EST\" \"2013-06-21 20:00:00 EDT\"\n[11] \"2013-09-28 06:00:00 EDT\" \"2013-12-07 11:00:00 EST\"\n[13] \"2013-06-26 15:00:00 EDT\" \"2013-07-30 22:00:00 EDT\"\n[15] \"2013-11-05 13:00:00 EST\" \"2013-12-22 23:00:00 EST\"\n[17] \"2013-10-15 15:00:00 EDT\" \"2013-04-19 16:00:00 EDT\"\n[19] \"2013-01-07 16:00:00 EST\" \"2013-11-05 21:00:00 EST\"\n[1] \"6916 unique entries not displayed\"\n[1] \"_____________________\"\n\n\nWarning: Not all unique entries displayed for these non-numeric cols: tailnum,\ndest, time_hour\n\nflights &lt;- as_tibble(flights)\nflights\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\nNow inspect unique values in each column to flights tibble\nUtilsDataRSV::view_cols(flights)\n\n[1] \"year\"\n[1] 1672\n[1] \"_____________________\"\n[1] \"month\"\n[1]  2  4 10  5  3\n[1] \"_____________________\"\n[1] \"day\"\n[1] 11 23  1 30 19\n[1] \"_____________________\"\n[1] \"dep_time\"\n[1] 1928 1618 1339  144   NA\n[1] \"_____________________\"\n[1] \"sched_dep_time\"\n[1]  949 1959 1708 1855 2021\n[1] \"_____________________\"\n[1] \"dep_delay\"\n[1] 446 126 330 273  NA\n[1] \"_____________________\"\n[1] \"arr_time\"\n[1]  847  200 1642 1131   NA\n[1] \"_____________________\"\n[1] \"sched_arr_time\"\n[1] 1638 2307  846 1908 1551\n[1] \"_____________________\"\n[1] \"arr_delay\"\n[1]  94 390 362 538  NA\n[1] \"_____________________\"\n[1] \"carrier\"\n [1] \"AA\" \"OO\" \"HA\" \"FL\" \"DL\" \"US\" \"WN\" \"AS\" \"B6\" \"YV\" \"EV\" \"VX\" \"F9\" \"MQ\" \"9E\"\n[16] \"UA\"\n[1] \"_____________________\"\n[1] \"flight\"\n[1] 4031 4510 1945 3136 2568\n[1] \"_____________________\"\n[1] \"tailnum\"\n [1] \"N255WN\" \"N111US\" \"N17115\" \"N33182\" \"N725UW\" \"N76062\" \"N15555\" \"N589AS\"\n [9] \"N430UA\" \"N923AT\" \"N511MJ\" \"N3730B\" \"N3DSAA\" \"N660DL\" \"N645JB\" \"N318AS\"\n[17] \"N566AS\" \"N8672A\" \"N910DE\" NA      \n[1] \"4024 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"origin\"\n[1] \"LGA\" \"EWR\" \"JFK\"\n[1] \"_____________________\"\n[1] \"dest\"\n [1] \"ORD\" \"BHM\" \"OMA\" \"TYS\" \"DFW\" \"AUS\" \"SBN\" \"XNA\" \"SAN\" \"TUL\" \"ILM\" \"RIC\"\n[13] \"IAD\" \"SYR\" \"BDL\" \"SJU\" \"LGA\" \"LAS\" \"MCI\" \"JAC\"\n[1] \"85 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"air_time\"\n[1] 579 192 394 145  NA\n[1] \"_____________________\"\n[1] \"distance\"\n[1] 1608 1017  828 1107 1020\n[1] \"_____________________\"\n[1] \"hour\"\n[1] 20 10 11 19 14\n[1] \"_____________________\"\n[1] \"minute\"\n[1]  9 49 16 23  6\n[1] \"_____________________\"\n[1] \"time_hour\"\n [1] \"2013-09-14 08:00:00 EDT\" \"2013-02-17 22:00:00 EST\"\n [3] \"2013-04-16 22:00:00 EDT\" \"2013-08-30 06:00:00 EDT\"\n [5] \"2013-01-02 11:00:00 EST\" \"2013-06-22 13:00:00 EDT\"\n [7] \"2013-02-16 22:00:00 EST\" \"2013-01-22 22:00:00 EST\"\n [9] \"2013-02-22 16:00:00 EST\" \"2013-02-08 17:00:00 EST\"\n[11] \"2013-07-23 17:00:00 EDT\" \"2013-12-23 23:00:00 EST\"\n[13] \"2013-09-23 13:00:00 EDT\" \"2013-03-19 22:00:00 EDT\"\n[15] \"2013-02-11 05:00:00 EST\" \"2013-07-18 10:00:00 EDT\"\n[17] \"2013-11-11 13:00:00 EST\" \"2013-01-15 07:00:00 EST\"\n[19] \"2013-11-19 21:00:00 EST\" \"2013-08-23 23:00:00 EDT\"\n[1] \"6916 unique entries not displayed\"\n[1] \"_____________________\"\n\n\nWarning: Not all unique entries displayed for these non-numeric cols: tailnum,\ndest, time_hour\nbelow is the code demonstration:\nflights |&gt; \n  filter(month == \"1\") |&gt;  #Filter the data to include only flights from January\n  group_by(carrier) |&gt; #Group the data  to perform calc. for each carrier.\n  summarise(\n    sd_distance = sd(distance, na.rm=T),\n  ) |&gt; \n  #logical checks if either is TRUE row kept \nfilter(is.na(sd_distance)| sd_distance == 0)\n\n# A tibble: 5 × 2\n  carrier sd_distance\n  &lt;chr&gt;         &lt;dbl&gt;\n1 AS                0\n2 F9                0\n3 HA                0\n4 OO               NA\n5 YV                0\nThe code filters January flights to find carriers with either NA or 0 standard deviations, displaying relevant results.\nflights |&gt; \n  summarise(\n    count = sum(dep_delay &gt;0 & arr_delay &lt;=0, na.rm = T),\n    total_flights = n(),\n    proportion = count/total_flights\n  )\n\n# A tibble: 1 × 3\n  count total_flights proportion\n  &lt;int&gt;         &lt;int&gt;      &lt;dbl&gt;\n1 35442        336776      0.105\nnote: summarise is helpful for calculating summary statistics for the entire dataset/ groups\nlibrary(dplyr)  \nflights\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\nmult_flights &lt;- flights |&gt;   \n  group_by(origin, dest) |&gt;  \n  #summarise(num_airlines = n_distinct(carrier), .group = 'drop') %&gt;% \n  filter(n_distinct(carrier) &gt; 1) |&gt;   \n  select(origin, dest, carrier) |&gt;   \ndistinct()\nmult_flights \n\n# A tibble: 343 × 3\n# Groups:   origin, dest [128]\n   origin dest  carrier\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 JFK    MIA   AA     \n 2 LGA    ATL   DL     \n 3 EWR    ORD   UA     \n 4 EWR    FLL   B6     \n 5 LGA    IAD   EV     \n 6 JFK    MCO   B6     \n 7 LGA    ORD   AA     \n 8 JFK    TPA   B6     \n 9 JFK    LAX   UA     \n10 EWR    SFO   UA     \n# ℹ 333 more rows\nlibrary(dplyr)  # Load dplyr for data manipulation  \n\n# Create a summarized list of routes with any airline (if needed)  \nunique_routes &lt;- mult_flights |&gt;   \n  group_by(origin, dest) |&gt;   \n  summarise()  # This will keep only unique routes  \n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n# Calculate average arrival delays for airlines on identified multi-airline routes using join  \navg_arrival &lt;- flights |&gt;   \n  \n  # Join the flights dataset with the unique routes on origin and dest  \n  inner_join(unique_routes,   \n             by = c(\"origin\", \"dest\")) |&gt;  # Joining on origin and dest  \n  \n  group_by(origin, dest, carrier) |&gt;   # Group by origin, destination, and carrier  \n  summarise(mean_arr_delay = mean(arr_delay, na.rm = TRUE), .groups = 'drop')  # Calculate mean arrival delay  \n\n# Display the average arrival delays  \navg_arrival\n\n# A tibble: 343 × 4\n   origin dest  carrier mean_arr_delay\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1 EWR    ATL   9E               -6.25\n 2 EWR    ATL   DL               10.0 \n 3 EWR    ATL   EV               19.5 \n 4 EWR    ATL   UA               10.5 \n 5 EWR    AUS   UA                4.28\n 6 EWR    AUS   WN              -11.2 \n 7 EWR    BDL   EV                6.78\n 8 EWR    BDL   UA               22.6 \n 9 EWR    BNA   EV               17.7 \n10 EWR    BNA   WN               -2.13\n# ℹ 333 more rows\nbest_worst &lt;- avg_arrival |&gt;   \n  group_by(origin, dest) |&gt;   \n  summarise(best_airline = carrier[which.min(mean_arr_delay)],  \n            best_delay = min(mean_arr_delay),  \n            \n            worst_airline = carrier[which.max(mean_arr_delay)],  \n            worst_delay = max(mean_arr_delay),\n            \n            difference = max(mean_arr_delay) - min(mean_arr_delay)) \n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\nbest_worst\n\n# A tibble: 128 × 7\n# Groups:   origin [3]\n   origin dest  best_airline best_delay worst_airline worst_delay difference\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n 1 EWR    ATL   9E               -6.25  EV                  19.5       25.8 \n 2 EWR    AUS   WN              -11.2   UA                   4.28      15.5 \n 3 EWR    BDL   EV                6.78  UA                  22.6       15.8 \n 4 EWR    BNA   WN               -2.13  EV                  17.7       19.8 \n 5 EWR    BOS   EV               -4.01  B6                   6.87      10.9 \n 6 EWR    BWI   WN                5.95  EV                  20.1       14.1 \n 7 EWR    CHS   UA              -14     EV                  16.2       30.2 \n 8 EWR    CLE   EV               -3.71  UA                   5.97       9.68\n 9 EWR    CLT   US                0.920 EV                  20.5       19.6 \n10 EWR    CVG   9E                1.40  EV                  21.2       19.8 \n# ℹ 118 more rows\nbest_worst |&gt;   \n  filter(difference == max(difference)) \n\n# A tibble: 2 × 7\n# Groups:   origin [2]\n  origin dest  best_airline best_delay worst_airline worst_delay difference\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n1 EWR    STL   WN                13.6  UA                    110       96.4\n2 JFK    ATL   9E                 1.40 EV                    128      127.\nThe difference in arrival delays between these airlines could be due to weather-related factors which might affect some airlines more than others.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Prac Day 4</span>"
    ]
  },
  {
    "objectID": "prac-day-four.html#question-7-identify-all-columns-with-missing-entries-typos-and-any-other-inconsistencies-in-the-dataset-below",
    "href": "prac-day-four.html#question-7-identify-all-columns-with-missing-entries-typos-and-any-other-inconsistencies-in-the-dataset-below",
    "title": "3  Prac Day 4",
    "section": "4.1 Question 7 Identify all columns with missing entries, typos and any other inconsistencies in the dataset below",
    "text": "4.1 Question 7 Identify all columns with missing entries, typos and any other inconsistencies in the dataset below\nFirst we read in the dataset into object data\n\ndata &lt;- structure(list(id = c(\"id_1\", \"id_2\", \"id_3\", \"id_4\", \"id_5\", \n\"id_6\", \"id_7\", \"id_8\", \"id_9\", \"id_10\", \"id_11\", \"id_12\", \"id_13\", \n\"id_14\", \"id_15\", \"id_16\", \"id_17\", \"id_18\", \"id_19\", \"id_20\", \n\"id_21\", \"id_22\", \"id_23\", \"id_24\", \"id_25\", \"id_26\", \"id_27\", \n\"id_28\", \"id_29\", \"id_30\", \"id_31\", \"id_32\", \"id_33\", \"id_34\", \n\"id_35\", \"id_36\", \"id_37\", \"id_38\", \"id_39\", \"id_40\", \"id_41\", \n\"id_42\", \"id_43\", \"id_44\", \"id_45\", \"id_46\", \"id_47\", \"id_48\", \n\"id_49\", \"id_50\"), age = c(50L, 34L, 70L, 33L, 22L, 61L, 69L, \n73L, 62L, 56L, 71L, 33L, 73L, 44L, 45L, 46L, 24L, 70L, 46L, 76L, \n47L, 76L, 28L, 48L, 54L, 27L, 45L, 26L, 61L, 28L, 38L, 55L, 33L, \n36L, 62L, 58L, 72L, 31L, 34L, 51L, 61L, 64L, 26L, 28L, 60L, 29L, \n42L, 46L, 79L, 72L), gender = c(\"male\", \"male\", \"male\", \"female\", \n\"female\", \"male\", \"female\", \"male\", \"male\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"male\", \"male\", \"male\", \"female\", \n\"male\", \"male\", \"male\", \"male\", \"female\", \"femal\", \"male\", \"female\", \n\"female\", \"female\", \"female\", \"male\", \"female\", \"female\", \"female\", \n\"male\", \"male\", \"female\", \"male\", \"female\", \"female\", \"male\", \n\"female\", \"female\", \"male\", \"male\", \"female\", \"male\", \"male\", \n\"male\", \"female\"), height = c(174.4, 197.7, 174.1, 194.5, NA, \n180.4, 170.5, 157.4, 196.8, 165.1, 153, 197.4, 186, 157.1, 177.5, \n197.7, 179.3, 170.2, 182.4, NA, 165.4, 161, 168.5, 199.2, 157.7, \n154.6, 157.1, 184.5, 181, 194.6, 183.6, 186.9, 176.1, 183, 191.1, \n189.3, 199, 172, 165.6, 170.5, 150.5, 159.2, 192.1, 161.6, 162, \n153.8, 162.3, 186.6, 192.4, 174.9), weight = c(69.4, 62.3, 55.6, \n69.5, 78.6, 60.8, 72.2, 60.9, 75.1, 67.7, 82.5, 68.7, 67.8, 76.7, \n87, 61.1, 70.6, 63.3, 81.5, 59.2, 93.2, 87.3, 83.4, 80.9, 68.6, \n76.5, 93.7, 79.1, 92, 65.6, 85.4, 63.3, 79.7, 74.1, 63.3, 78.2, \n95.7, 95.1, 63.7, 66.1, 99.3, 81, 96.9, 73.3, 70.3, 83, 57.6, \n78.6, 61.9, 98.1), blood_type = c(\"O\", \"A\", \"O\", \"O\", \"B\", \"AB\", \n\"O\", \"O\", \"O\", \"AB\", \"A\", \"O\", \"O\", \"O\", \"B\", \"A\", \"B\", \"AB\", \n\"O\", \"AB\", \"A\", \"AB\", \"O\", \"B\", \"A\", \"A\", \"B\", \"AB\", \"A\", \"B\", \n\"B\", \"A\", \"O\", \"O\", \"O\", \"B\", \"O\", \"A\", \"A\", \"B\", \"A\", \"O\", \"AB\", \n\"A\", \"A\", \"O\", \"O\", \"B\", \"A\", \"O\"), disease_status = c(\"diseased\", \n\"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"Healthy\", \"diseased\", \"healthy\", \"diseased\", \n\"healthy\", \"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"healthy\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"healthy\", \"diseased\", \"diseased\", \"healthy\", \n\"healthy\", \"healthy\", \"diseased\", \"diseased\", \"diseased\", \"healthy\", \n\"diseased\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \n\"diseased\", \"diseased\", \"diseased\", \"healthy\", \"healthy\", \"diseased\", \n\"diseased\"), cholesterol = c(228, 223, 213, 198, 166, 151, 195, \n199, 189, 196, 221, 156, 185, 230, 234, 174, 185, 236, 235, 180, \n165, 220, 160, 153, 250, 153, 184, 242, 212, 179, 224, 233, 181, \n199, 220, 214, 214, 248, 191, 162, 203, 173, 199, 187, 248, 189, \n173, 212, 164, 247), glucose = c(96, 78, 101, 119, 103, 91, 86, \nNA, 77, 80, 115, 85, 88, 109, NA, 71, 90, 94, 91, 87, 113, 93, \n97, 118, 109, 80, 85, 119, 99, 108, 89, 108, 97, 116, 79, 84, \n75, 81, 119, NA, 106, 109, 75, 82, 84, 75, 76, 120, 119, 77), \n    smoker = c(\"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"no\", \n    \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \n    \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \n    \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", \n    \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"yes\"), exercise = c(\"occasional\", \n    \"regular\", \"occasional\", \"regular\", \"none\", \"occasional\", \n    \"regular\", \"none\", \"occasional\", \"none\", \"occasional\", \"none\", \n    \"none\", \"regular\", \"occasional\", \"none\", \"regular\", \"regular\", \n    \"none\", \"occasional\", \"none\", \"occasional\", \"occasional\", \n    \"occasional\", \"regular\", \"occasional\", \"regular\", \"regular\", \n    \"regular\", \"occasional\", \"occasional\", \"none\", \"none\", \"regular\", \n    \"occasional\", \"occasional\", \"none\", \"none\", \"none\", \"none\", \n    \"occasional\", \"regular\", \"regular\", \"none\", \"regular\", \"occasional\", \n    \"occasional\", \"none\", \"occasional\", \"regular\"), income = c(84820L, \n    81547L, 22588L, 72490L, 74533L, 25338L, 41469L, 57315L, 63629L, \n    88662L, 62615L, 56261L, 58499L, 82232L, 77584L, 77275L, 38468L, \n    54510L, 91326L, 78611L, 31402L, 29586L, 21441L, 58269L, 84173L, \n    88295L, 37940L, 43750L, 69750L, 92356L, 82518L, 91455L, 68866L, \n    51178L, 68275L, 27689L, 35418L, 81318L, 62405L, 86851L, 25654L, \n    47553L, 74474L, 51409L, 22607L, 55360L, 96351L, 21516L, 41927L, \n    55810L), education = c(\"master\", \"bachelor\", \"PhD\", \"master\", \n    \"bachelor\", \"highschool\", \"PhD\", \"highschool\", \"PhD\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"bachelor\", \"PhD\", \"PhD\", \n    \"PhD\", \"bachelor\", \"master\", \"highschool\", \"PhD\", \"highschool\", \n    \"bachelor\", \"master\", \"highschool\", \"highschool\", \"master\", \n    \"master\", \"bachelor\", \"PhD\", \"highschool\", \"PhD\", \"master\", \n    \"master\", \"master\", \"PhD\", \"highschool\", \"master\", \"master\", \n    \"highschool\", \"bachelor\", \"highschool\", \"bachelor\", \"PhD\", \n    \"bachelor\", \"highschool\", \"master\", \"highschool\", \"bachelor\", \n    \"bachelor\"), region = c(\"North\", \"South\", \"North\", \"West\", \n    \"North\", \"West\", \"South\", \"South\", \"West\", \"South\", \"West\", \n    \"South\", \"West\", \"East\", \"North\", \"West\", \"North\", \"North\", \n    \"West\", \"North\", \"East\", \"West\", \"South\", \"North\", \"North\", \n    \"East\", \"East\", \"North\", \"North\", \"West\", \"South\", \"West\", \n    \"West\", \"East\", \"West\", \"North\", \"West\", \"North\", \"East\", \n    \"North\", \"West\", \"South\", \"South\", \"East\", \"North\", \"West\", \n    \"West\", \"East\", \"North\", \"East\"), marital_status = c(\"divorced\", \n    \"single\", \"divorced\", \"divorced\", \"divorced\", \"divorced\", \n    \"divorced\", \"married\", \"divorced\", \"married\", \"divorced\", \n    \"widowed\", \"married\", \"single\", \"widowed\", \"widowed\", \"single\", \n    \"divorced\", \"widowed\", \"widowed\", \"single\", \"married\", \"single\", \n    \"married\", \"widowed\", \"married\", \"single\", \"single\", \"widowed\", \n    \"married\", \"widowed\", \"divorced\", \"single\", \"married\", \"single\", \n    \"widowed\", \"widowed\", \"married\", \"widowed\", \"divorced\", \"married\", \n    \"married\", \"divorced\", \"single\", \"married\", \"widowed\", \"divorced\", \n    \"divorced\", \"single\", \"divorced\")), row.names = c(NA, -50L\n), class = c(\"tbl_df\", \"tbl\", \"data.frame\"))\n\ndata\n\n# A tibble: 50 × 15\n   id      age gender height weight blood_type disease_status cholesterol\n   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;\n 1 id_1     50 male     174.   69.4 O          diseased               228\n 2 id_2     34 male     198.   62.3 A          healthy                223\n 3 id_3     70 male     174.   55.6 O          healthy                213\n 4 id_4     33 female   194.   69.5 O          healthy                198\n 5 id_5     22 female    NA    78.6 B          healthy                166\n 6 id_6     61 male     180.   60.8 AB         healthy                151\n 7 id_7     69 female   170.   72.2 O          diseased               195\n 8 id_8     73 male     157.   60.9 O          healthy                199\n 9 id_9     62 male     197.   75.1 O          diseased               189\n10 id_10    56 female   165.   67.7 AB         Healthy                196\n# ℹ 40 more rows\n# ℹ 7 more variables: glucose &lt;dbl&gt;, smoker &lt;chr&gt;, exercise &lt;chr&gt;,\n#   income &lt;int&gt;, education &lt;chr&gt;, region &lt;chr&gt;, marital_status &lt;chr&gt;\n\n\nIdentify all columns with missing entries, typos and any other inconsistencies in the dataset above\n\n#convert dataset into a tibble \n\nlibrary(tibble)\nlibrary(utils)\ndata &lt;- as_tibble(data)\ndata\n\n# A tibble: 50 × 15\n   id      age gender height weight blood_type disease_status cholesterol\n   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;\n 1 id_1     50 male     174.   69.4 O          diseased               228\n 2 id_2     34 male     198.   62.3 A          healthy                223\n 3 id_3     70 male     174.   55.6 O          healthy                213\n 4 id_4     33 female   194.   69.5 O          healthy                198\n 5 id_5     22 female    NA    78.6 B          healthy                166\n 6 id_6     61 male     180.   60.8 AB         healthy                151\n 7 id_7     69 female   170.   72.2 O          diseased               195\n 8 id_8     73 male     157.   60.9 O          healthy                199\n 9 id_9     62 male     197.   75.1 O          diseased               189\n10 id_10    56 female   165.   67.7 AB         Healthy                196\n# ℹ 40 more rows\n# ℹ 7 more variables: glucose &lt;dbl&gt;, smoker &lt;chr&gt;, exercise &lt;chr&gt;,\n#   income &lt;int&gt;, education &lt;chr&gt;, region &lt;chr&gt;, marital_status &lt;chr&gt;\n\n#unique values in each column \nUtilsDataRSV::view_cols(data)\n\n[1] \"id\"\n [1] \"id_38\" \"id_5\"  \"id_36\" \"id_32\" \"id_33\" \"id_35\" \"id_19\" \"id_27\" \"id_18\"\n[10] \"id_8\"  \"id_41\" \"id_13\" \"id_26\" \"id_44\" \"id_46\" \"id_14\" \"id_43\" \"id_22\"\n[19] \"id_11\" \"id_24\"\n[1] \"30 unique entries not displayed\"\n[1] \"_____________________\"\n[1] \"age\"\n[1] 64 56 26 71 69\n[1] \"_____________________\"\n[1] \"gender\"\n[1] \"femal\"  \"male\"   \"female\"\n[1] \"_____________________\"\n[1] \"height\"\n[1] 199.0 181.0 157.7 186.0    NA\n[1] \"_____________________\"\n[1] \"weight\"\n[1] 82.5 70.3 81.0 80.9 95.1\n[1] \"_____________________\"\n[1] \"blood_type\"\n[1] \"A\"  \"AB\" \"O\"  \"B\" \n[1] \"_____________________\"\n[1] \"disease_status\"\n[1] \"healthy\"  \"Healthy\"  \"diseased\"\n[1] \"_____________________\"\n[1] \"cholesterol\"\n[1] 220 221 166 181 196\n[1] \"_____________________\"\n[1] \"glucose\"\n[1] 116  87  91  85  NA\n[1] \"_____________________\"\n[1] \"smoker\"\n[1] \"yes\" \"no\" \n[1] \"_____________________\"\n[1] \"exercise\"\n[1] \"occasional\" \"none\"       \"regular\"   \n[1] \"_____________________\"\n[1] \"income\"\n[1] 96351 57315 69750 27689 68866\n[1] \"_____________________\"\n[1] \"education\"\n[1] \"highschool\" \"master\"     \"bachelor\"   \"PhD\"       \n[1] \"_____________________\"\n[1] \"region\"\n[1] \"East\"  \"North\" \"South\" \"West\" \n[1] \"_____________________\"\n[1] \"marital_status\"\n[1] \"single\"   \"widowed\"  \"married\"  \"divorced\"\n[1] \"_____________________\"\n\n\nWarning: Not all unique entries displayed for these non-numeric cols: id\n\n\n\nMissing Values: found under height and glucose variables i.e. NA values\nInconsistencies: found under the “disease_status” for level healthy i.e. “healthy” “Healthy”\nTypos: found under gender i.e.\n\"femal\"  \"female\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Prac Day 4</span>"
    ]
  },
  {
    "objectID": "prac_2.html",
    "href": "prac_2.html",
    "title": "4  Prac 2",
    "section": "",
    "text": "4.1 LOWESS PRACTICAL\nThe goal of Lowess smoothing is to create a smooth curve that captures the underlying trend of the data while accounting for local structures and variation.\nThis is especially useful in datasets like noisy sine waves where the true relationship is obscured by noise",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prac 2</span>"
    ]
  },
  {
    "objectID": "prac_2.html#lowess-practical",
    "href": "prac_2.html#lowess-practical",
    "title": "4  Prac 2",
    "section": "",
    "text": "4.1.1 Steps to Implement Lowess Smoothing\n\nUnderstanding the data\n\nGoal: Gather the observed data pairs as (x1​,y1​),…,(xn​,yn​), where x represents the independent variable and y is the dependent variable. We will generate sequences for x and create the corresponding y values using a sine function with added noise.\n\n\nChoosing the Span\n\nGoal: Select a smoothing parameter (span) f where 0&lt;f&lt;1. This span determines how many neighboring points will influence the smoothed estimate for each xi\nCalculation k=⌈f⋅n⌉, where k is the number of closest neighbours used for point xi and n is the number of observations.\n\n\nComputing Weights - Goal: For each point xi , calculate the weight for each of its neighbors using the tricube kernel:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prac 2</span>"
    ]
  },
  {
    "objectID": "prac_2.html#practical-question",
    "href": "prac_2.html#practical-question",
    "title": "4  Prac 2",
    "section": "4.2 PRACTICAL QUESTION",
    "text": "4.2 PRACTICAL QUESTION\n\n#set seed to 1\nset.seed(1)\n\n#Generate simulated data \nn &lt;- 100\nx &lt;- seq(1:n)\ne &lt;- rnorm(n, mean = 0 , sd = 0.2)\ny &lt;- sin(x/10) + e\n\n#Implement the LOWESS Algorithm\ncustomLowess &lt;- function(x, y, f)\n{\n  nobs &lt;-  length(x)\n  smoothed_y &lt;- numeric(nobs) #Initialize storage for smoothed y values \n  \n  #determine k = number of closest neighbors based on the bandwidth (f)\n  k = ceiling(f * nobs)\n  \n  #compute weights \n  #Calculate dmax \n  for (i in 1:n){\n    #caclulate distance from current point \n    dist = abs(x - x[i]) #distance vector\n    sort_dist_indices &lt;-  order(dist) #give indices of sorted distance in ascending order \n    \n    #find k closest neighbours \n    near_indices &lt;- sort_dist_indices[1:k] #By taking the first k of these sorted indices, we get the indices of the nearest points\n    \n    #find corresponding co-ord for nearest neighbour points \n    x_neighbours &lt;-  x[near_indices]#closest points are at those indices\n    y_neighbours &lt;-  y[near_indices]\n    nearest_dist &lt;- dist[near_indices]\n    \n    #Compute weights\n    d_max &lt;- max(nearest_dist)\n    wj &lt;- (1-(abs(nearest_dist)/d_max)^3)^3\n    wj[abs(nearest_dist) &gt;= d_max] &lt;- 0 #condition is TRUE, the corresponding weight in the weights vector is set to 0\n    \n    X &lt;- cbind(1, x_neighbours)\n    W &lt;- diag(wj) # Create diagonal weight matrix  \n    \n    #regression estimates\n    beta_hat &lt;- solve(t(X) %*% W %*% X) %*% t(X) %*% W %*% y_neighbours\n    \n    smoothed_y[i] &lt;- beta_hat[1] + beta_hat[2] %*% x[i]\n    \n  }\n  return(list(x = x, smoothed_y =  smoothed_y))\n}\n\nCalling the above customLowess function and compare it with the built-in lowess() function with the same f value. Note: iter argument to 0\nBelow displays the plotted results for the customLowess function for f = 0.5\n\nlibrary(graphics)\nlibrary(ggplot2)\nresult &lt;- customLowess(x, y, f = 0.5)\n\n# Plot the original data  \nplot(y ~ x, main = \"LOWESS Smoothing\", xlab = \"X-axis\", ylab = \"Y-axis\", pch = 19) \n\n#add lowess line \nlines(result$x, result$smoothed_y, col = 'blue', lwd = 2)\n\n\n\n\n\n\n\n\nBelow displays the plotted results or the build-in Lowess function for f = 0.5\n\n# Plot the original data  \nplot(y ~ x, main = \"LOWESS Smoothing\", xlab = \"X-axis\", ylab = \"Y-axis\", pch = 19) \n\nlines(lowess(x, y, f=0.5, iter = 0),col = 'red', lwd = 2)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prac 2</span>"
    ]
  }
]